import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
import random
import gzip
import xml.etree.ElementTree as ET
import os
import subprocess
import shutil
import json
import concurrent.futures


def get_valid_urls(url, break_url):
    """
    Get valid urls from sitemap.xml. Note: only links after group-49 are valid for download.
        - url: the link to stemap.xml
        - break_url: the url link to the group-49

    >>> url = "https://apkpure.com/sitemap.xml"
    >>> break_url = "https://apkpure.com/sitemaps/group-49.xml.gz"
    >>> valid_urls = get_valid_urls(url, break_url)
    >>> valid_urls[0]
    'https://apkpure.com/sitemaps/art_and_design.xml.gz'
    >>> len(valid_urls)
    7774
    """
    page = requests.get(url)
    page_text = page.text
    soup = BeautifulSoup(page.text, features="lxml")
    urls = [element.get_text() for element in soup.find_all('loc')]
    break_point = urls.index(break_url)
    valid_urls = urls[break_point+1:]
    return valid_urls

def sample(num_to_sample, valid_urls):
    """
    sample out urls depending on the number of apps that we need.
        - num_to_sample: number of apps needed to be sampled out.
        - valid_urls: the valid urls list passed in from the above functions.

    >>> num_to_sample = 10
    >>> url = "https://apkpure.com/sitemap.xml"
    >>> break_url = "https://apkpure.com/sitemaps/group-49.xml.gz"
    >>> valid_urls = get_valid_urls(url, break_url)
    >>> sampled = sample(num_to_sample, valid_urls)
    >>> len(sampled)
    10
    """
    ## sample without replacement
    sampled_urls = random.sample(valid_urls, k = num_to_sample)
    return sampled_urls

def getAllLinksGZip(target_url):
    """
    From all GZip file links, sample one out and get all the url in it.
        - target_url: one of url in the sampled_urls

    >>> target_url = 'https://apkpure.com/sitemaps/game_arcade-49.xml.gz'
    >>> all_links = getAllLinksGZip(target_url)
    >>> len(all_links)
    1000
    """
    #target_url = random.sample(sampled_urls, 1)[0]
    resp = requests.get(target_url)
    data = gzip.decompress(resp.content)
    soup = BeautifulSoup(data, features='lxml')
    root = ET.fromstring(data)
    ## get all links in the sampled GZip xml file
    all_links = [i[0].text for i in root]
    return all_links


def getDownloadLink(all_links):
    """
    From all App links provided by decompressing the gZip file, sample one out and get the download link within.
        - all_links: all the links in one GZip xml file.

    >>> target_url = 'https://apkpure.com/sitemaps/game_arcade-49.xml.gz'
    >>> all_links = getAllLinksGZip(target_url)
    >>> download_link, title = getDownloadLink(all_links)
    >>> len(download_link) > 0
    True
    
    """
    app_page = random.sample(all_links, 1)[0]
    app_page_soup = BeautifulSoup(requests.get(app_page).text, features="lxml")
    a = app_page_soup.findAll("a", {"class": "da"})[0]
    try:
        ## if it has rel, if means that the app cannot be downloaded. Then recursively call this function to get a 
        ## valid link
        check = a['rel']
        return getDownloadLink(all_links)
    except:
        href = 'https://apkpure.com' + a['href']
        href_soup = BeautifulSoup(requests.get(href).text, features="lxml")
        title = app_page_soup.findAll("div", {"class": "title-like"})[0].find('h1').text
        href_a = href_soup.findAll("a", {"id": "download_link"})[0]
        return href_a['href'], title

def to_APK(download_link, title, apk_dir):
    """
    write to apk file.
        - download_link: the link to download the apk file of the app.
        - title: the name of the app.
        - apk_dir: the directory to write to.
    """
    apk_file = requests.get(download_link)
    if not os.path.exists(apk_dir):
        os.mkdir(apk_dir)
    with open(apk_dir+'/' + title + '.apk', 'wb') as f:
        f.write(apk_file.content)

def to_Smali(title, apk_dir, smali_dir):
    """
    get the smali code from apk file.
        - title: the name of the app.
        - apk_dir: the directory to get the apk file.
        - smali_dir: the directory to write to.
    """
    if not os.path.exists(smali_dir):
        os.mkdir(smali_dir)
    subprocess.run(['apktool', 'd', apk_dir+'/'+ title + '.apk', '-o', smali_dir + '/'+ title], capture_output=True)

def del_Dir(title, smali_dir):
    """
    Only Smali directory and xml files are left. Delete irrelevant directories.
        - title: the name of the app, which is also the folder name containing the smali code.
        - smali_dir: the directory containing all the apps' smali code.
    """
    all_directories = os.listdir( smali_dir + '/'+title)
    to_be_del = [directory for directory in all_directories if not (('.xml' in directory) or ("smali" in directory))]
    for directory in to_be_del:
        shutil.rmtree(smali_dir + '/'+ title+ '/' + directory, ignore_errors=True)

def get_data(url, break_url, num_to_sample, apk_dir, smali_dir):
    valid_urls = get_valid_urls(url, break_url)
    sampled_urls = sample(num_to_sample, valid_urls)
    
    def to_download(target_url):
        """
        This method download the apk files from the given url and convert it to smali files.
            - target_url: the url links to the downloading website.
        """
        print("start downloading...")
        all_links = getAllLinksGZip(target_url)
        download_link, title = getDownloadLink(all_links)
        to_APK(download_link, title, apk_dir)
        to_Smali(title, apk_dir, smali_dir)
        del_Dir(title, smali_dir)
        print("finish downloading...")
        
    with concurrent.futures.ThreadPoolExecutor() as executor:
        results = executor.map(to_download, sampled_urls)
        
#     for target_url in sampled_urls:
#         all_links = getAllLinksGZip(target_url)
#         download_link, title = getDownloadLink(all_links)
#         to_APK(download_link, title, apk_dir)
#         to_Smali(title, apk_dir, smali_dir)
#         del_Dir(title, smali_dir)
        
if __name__ == '__main__':
    cfg = json.load(open('data-injestion.json'))
    get_data(**cfg)
