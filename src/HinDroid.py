import glob
import numpy as np
import pandas as pd
import networkx as nx
import os
import re
from itertools import combinations_with_replacement
from itertools import combinations
import random
import concurrent.futures
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import scipy.sparse
from sklearn.metrics import f1_score
from multiprocessing import Process, Manager
import json

def true_pos_rate(y_true, y_pred):
    """
    Calculate the true postive (indicated by 1) rate of the prediction.
    Args:
        y_true: true label of data
        y_pred: prediction label of data
    """
    true_pos = np.sum(np.array(y_true)*np.array(y_pred))
    all_pos = sum(y_true)
    try:
        return true_pos/all_pos
    except:
        return 0

def dict_append_set(dict_, key, set_):
    """
    Append a key set pair to a dictionary of sets. First need to check if the key is already in the dict

    Args:
        dict_: The dictionary to be appended
        key: Key to be appended
        set_: value to be appended
    """
    if key in dict_.keys():
        dict_[key] = dict_[key].union(set_)
    else:
        dict_[key] = set_

def get_all_smali(all_smali):
    """
    It combines all smali files in all directionries of an APP into one big text string.

    Args:
        all_smali: a list of all smali files.
    """
    all_smali_in_one = ''
    for file in all_smali:
        with open(file) as f:
            content = f.read().strip('\n')

        all_smali_in_one += content + '\t0\n'
    all_smali_in_one = all_smali_in_one.replace('\n', '')
    return all_smali_in_one

def update_B(B, codeblock_list):
    """
    Update the dictionary B.

    Args:
        B: the api to api dictionary in same code block.
        codeblock_list: a list of all codeblocks of this APP.
    """
    #loop through each code block, find all invoke lines and then the api in the invoke line.
    for codeblock in codeblock_list:
        invoke_list = set(re.findall(r"(invoke-.*?->.*?)\s",codeblock))
        # api_in_block contains all APIs in this block.
        api_in_block = set([invoke.split()[-1] for invoke in invoke_list])
        # all api in api_in_block should have the set appended to its same-block-apis values.
        for api in api_in_block: dict_append_set(B, api, api_in_block)

def update_A(A, app, all_invoke_tuples):
    """
    Update the dictionary A.

    Args:
        A: the app to api dictionary.
        all_invoke_tuples: a list of (invoke method, api, package)
    """
    # extract the second element of each tuple in all_invoke_tuples
    A[app] = set([tuple_[1] for tuple_ in all_invoke_tuples])

def update_P(P, all_invoke_tuples):
    """
    Update the dictionary P.

    Args:
        P: the api to api dictionary in same package.
        all_invoke_tuples: a list of (invoke method, api, package)
    """
    package_api_dict = dict()
    for invoke_method, api, package in all_invoke_tuples:
        package_api_dict.setdefault(package, set()).add(api)

    # Values of the package dictionary are set of APIs that are within the same package name
    for api_set in package_api_dict.values():
        # an api_set contains all apis that co-exist in a package
        # all api in api_set should have the api_lsit set appended to its same-package-apis values.
        for api in api_set: dict_append_set(P, api, api_set)


def update_with_new_app(app_dir, A, B, P):
    """
    Update dictionaries A, B, P when a new App comes in.

    Args:
        A: the app to api dictionary.
        B: the api to api dictionary in same package.
        P: the api to api dictionary in same package.
        app_dirs: a new app that comes in (name string). If it's malware, then the app is a directory of the malware rather than name
    """
    print("APP: ", app_dir.split('/')[-1])

    ## this line get all smali files that is within this app directory
    all_smali = glob.glob(app_dir + "/**/*.smali", recursive = True)

    all_smali_in_one = get_all_smali(all_smali)

    codeblock_list = re.findall(r'\.method.*?\.end method', all_smali_in_one)

    update_B(B, codeblock_list)

    ## get all invoke calls from the file
    all_invoke_list = re.findall(r"(invoke-.*?->.*?)\s",all_smali_in_one)
    ## split the all_invoke_list into a list of tuples. Tuple format: (invoke method, api, package)
    all_invoke_tuples = [(invoke.split()[0], invoke.split()[-1], invoke.split()[-1].split('->')[0])
                         for invoke in all_invoke_list]

    update_A(A, app_dir, all_invoke_tuples)
    update_P(P, all_invoke_tuples)

    print("finished")

def sample_malwares(num_to_sample):
    """
    Sample a certain number of malwares from the given directory.

    Args:
        num_to_sample: the number of malwares that needs to be sampled
        Returns: the list of malware directories.
    """
    malware_dirs = random.sample(glob.glob('/datasets/dsc180a-wi20-public/Malware/amd_data_smali/*/*/*'), num_to_sample)
    return malware_dirs

def align_key_order(input_dict, key_order):
    """
    This method create a new dictionary by aligning the key order to the given list.

    Args:
        input_dict: the dictionary whose key order needs to be aligned.
        key_order: the key order that needed to be aligned to.
    """
    to_Return = dict()
    for key in key_order:
        to_Return[key] = input_dict[key]
    return to_Return

def update_A_test(A_test, app_dir):
    """
    It update the testing A dictionary when an new App in test data set comes in.

    Args:
        A_test: the app to api dictionary for test data.
        test_app_dir: the directory of a new app in test dataset.
    """
    print("APP: ", app_dir.split('/')[-1])

    ## this line get all smali files that is within this app directory
    all_smali = glob.glob(app_dir + "/**/*.smali", recursive = True)

    all_smali_in_one = get_all_smali(all_smali)

    ## get all invoke calls from the file
    all_invoke_list = re.findall(r"(invoke-.*?->.*?)\s",all_smali_in_one)
    ## split the all_invoke_list into a list of tuples. Tuple format: (invoke method, api, package)
    all_invoke_tuples = [(invoke.split()[0], invoke.split()[-1], invoke.split()[-1].split('->')[0])
                         for invoke in all_invoke_list]

    update_A(A_test, app_dir, all_invoke_tuples)

    print("finished")

def HinDroid(num_malwares, num_benign, test):
    benignware_dirs = glob.glob("./smali_files/*", recursive = True)
    malware_dirs = sample_malwares(num_malwares)
    benignware_dirs = random.sample(benignware_dirs, num_benign)
    X_data = benignware_dirs + malware_dirs
    ## 0 indicate not malware while 1 indicate malware.
    y_data = [0]*len(benignware_dirs)+[1]*len(malware_dirs)
    


    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.33, random_state=42)
    
    if test:
        total_len = len(X_train)
        y_train = [0]*(total_len//2) + [1]*(total_len - total_len//2)


    ## Train Matrix Preparation
    A = dict()
    B = dict()
    P = dict()

    i = 0
    for app in X_train:
        print(i)
        update_with_new_app(app, A, B, P)
        i+=1

    app_seq = list(A.keys())
    mlb = MultiLabelBinarizer(sparse_output=True)
    A_matrix = mlb.fit_transform(list(A.values()))
    api_seq = mlb.classes_.tolist()

    aligned_B = align_key_order(B, api_seq)

    mlb_2 = MultiLabelBinarizer(sparse_output=True, classes = api_seq)
    B_matrix = mlb.fit_transform(list(aligned_B.values()))
    aligned_P = align_key_order(P, api_seq)
    P_matrix = mlb.fit_transform(list(aligned_P.values()))

    result_dir = json.load(open('./config/env.json'))['output-path']
    if not os.path.exists(result_dir): os.mkdir(result_dir)
    scipy.sparse.save_npz(result_dir + '/A.npz', A_matrix)
    scipy.sparse.save_npz(result_dir + '/B.npz', B_matrix)
    scipy.sparse.save_npz(result_dir + '/P.npz', P_matrix)

    A_sparse = A_matrix
    B_sparse = B_matrix
    P_sparse = P_matrix

    ## Test Matrix Preparation
    A_test = dict()
    for app in X_test: update_A_test(A_test, app)
    mlb_test = MultiLabelBinarizer(sparse_output=True, classes = api_seq)
    A_test_sparse = mlb_test.fit_transform(list(A_test.values()))
    scipy.sparse.save_npz(result_dir + '/A_test.npz', A_test_sparse)

    ## Training and Testing Process
    AA = []
    svc = SVC(kernel='precomputed')
    kernel_train = (A_sparse * (A_sparse.transpose())).todense()
    svc.fit(kernel_train, y_train)
    y_pred_train = svc.predict(kernel_train)
    AA.append(accuracy_score(y_train, y_pred_train))
    AA.append(true_pos_rate(y_train, y_pred_train))

    kernel_test = (A_test_sparse * (A_sparse.transpose())).todense()
    y_pred_test = svc.predict(kernel_test)
    AA.append(accuracy_score(y_test, y_pred_test))
    AA.append(true_pos_rate(y_test, y_pred_test))

    ABA = []
    svc = SVC(kernel='precomputed')
    kernel_train = (A_sparse * B_sparse * (A_sparse.transpose())).todense()
    svc.fit(kernel_train, y_train)
    y_pred_train = svc.predict(kernel_train)
    ABA.append(accuracy_score(y_train, y_pred_train))
    ABA.append(true_pos_rate(y_train, y_pred_train))

    kernel_test = (A_test_sparse * B_sparse * (A_sparse.transpose())).todense()
    y_pred_test = svc.predict(kernel_test)
    ABA.append(accuracy_score(y_test, y_pred_test))
    ABA.append(true_pos_rate(y_test, y_pred_test))

    APA = []
    svc = SVC(kernel='precomputed')
    kernel_train = (A_sparse * P_sparse * (A_sparse.transpose())).todense()
    svc.fit(kernel_train, y_train)
    y_pred_train = svc.predict(kernel_train)
    APA.append(accuracy_score(y_train, y_pred_train))
    APA.append(true_pos_rate(y_train, y_pred_train))

    kernel_test = (A_test_sparse * P_sparse * (A_sparse.transpose())).todense()
    y_pred_test = svc.predict(kernel_test)
    APA.append(accuracy_score(y_test, y_pred_test))
    APA.append(true_pos_rate(y_test, y_pred_test))

    APBPA = []
    svc = SVC(kernel='precomputed')
    kernel_train = (A_sparse * P_sparse * B_sparse * (P_sparse.transpose()) * (A_sparse.transpose())).todense()
    svc.fit(kernel_train, y_train)
    y_pred_train = svc.predict(kernel_train)
    APBPA.append(accuracy_score(y_train, y_pred_train))
    APBPA.append(true_pos_rate(y_train, y_pred_train))

    kernel_test = (A_test_sparse * P_sparse * B_sparse * (P_sparse.transpose()) * (A_sparse.transpose())).todense()
    y_pred_test = svc.predict(kernel_test)
    APBPA.append(accuracy_score(y_test, y_pred_test))
    APBPA.append(true_pos_rate(y_test, y_pred_test))

    df = pd.DataFrame(columns = ['Train Acc.', 'Test Acc.', 'Train True Postive Rate', 'Test True Postive Rate'],
                      index = ['AA', 'ABA', 'APA', 'APBPA'])

    df.loc['AA',:] = AA
    df.loc['ABA',:] = ABA
    df.loc['APA',:] = APA
    df.loc['APBPA',:] = APBPA

    df.to_csv(result_dir+"/HinDroid_result.csv")
